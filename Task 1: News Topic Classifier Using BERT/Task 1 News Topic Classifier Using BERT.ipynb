{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32474e3c-23bd-4c26-a099-763decdd1dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers>=4.35 in d:\\anaconda\\lib\\site-packages (4.55.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: datasets>=2.19 in d:\\anaconda\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: evaluate>=0.4 in d:\\anaconda\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: accelerate>=0.26 in d:\\anaconda\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (2024.9.11)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers>=4.35) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\anaconda\\lib\\site-packages (from datasets>=2.19) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anaconda\\lib\\site-packages (from datasets>=2.19) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (from datasets>=2.19) (2.3.1)\n",
      "Requirement already satisfied: xxhash in d:\\anaconda\\lib\\site-packages (from datasets>=2.19) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\anaconda\\lib\\site-packages (from datasets>=2.19) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\anaconda\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (2024.6.1)\n",
      "Requirement already satisfied: psutil in d:\\anaconda\\lib\\site-packages (from accelerate>=0.26) (5.9.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\anaconda\\lib\\site-packages (from accelerate>=0.26) (2.7.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\anaconda\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.35) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->transformers>=4.35) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->transformers>=4.35) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->transformers>=4.35) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->transformers>=4.35) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch>=2.0.0->accelerate>=0.26) (75.1.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers>=4.35) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas->datasets>=2.19) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas->datasets>=2.19) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas->datasets>=2.19) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.19) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install -q evaluate\n",
    "%pip install -U \"transformers>=4.35\" \"datasets>=2.19\" \"evaluate>=0.4\" \"accelerate>=0.26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b6d9fa-5085-4b93-bfd4-d0edbaa80a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification, \n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    IntervalStrategy,\n",
    ")\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a8007e-0827-46c0-8fb0-e1c34f92dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load dataset\n",
    "ds = load_dataset(\"sh0416/ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6834f8f4-f8c1-4eb7-a343-057822a4e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Splits\n",
    "if \"validation\" in ds:\n",
    "    train_ds, val_ds = ds[\"train\"], ds[\"validation\"]\n",
    "else:\n",
    "    split = ds[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "    train_ds, val_ds = split[\"train\"], split[\"test\"]\n",
    "\n",
    "eval_ds = ds[\"test\"] if \"test\" in ds else val_ds\n",
    "test_ds = ds[\"test\"] if \"test\" in ds else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ce5d4a3-c366-4839-aa56-7891e7a82406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Label column + names\n",
    "features = train_ds.features\n",
    "label_col = next((n for n, f in features.items() if isinstance(f, ClassLabel)), None)\n",
    "if label_col is None:\n",
    "    label_col = \"label\" if \"label\" in features else \"labels\" if \"labels\" in features else None\n",
    "assert label_col is not None, f\"No label column found. Features: {features}\"\n",
    "\n",
    "# Rename label column to 'labels' for consistency\n",
    "def rename_labels_column(ds, old_label_col):\n",
    "    if old_label_col != \"labels\" and old_label_col in ds.column_names:\n",
    "        return ds.rename_column(old_label_col, \"labels\")\n",
    "    return ds\n",
    "\n",
    "train_ds = rename_labels_column(train_ds, label_col)\n",
    "val_ds = rename_labels_column(val_ds, label_col)\n",
    "if test_ds is not None:\n",
    "    test_ds = rename_labels_column(test_ds, label_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcde4645-2db6-48bd-b451-c92411eec24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Text columns auto-detect\n",
    "def guess_text_cols(cols):\n",
    "    lmap = {c.lower(): c for c in cols}\n",
    "    candidates = [\n",
    "        [\"text\"],                    # standard\n",
    "        [\"title\", \"description\"],    # common variant\n",
    "        [\"title\", \"text\"],\n",
    "        [\"headline\"],\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        if all(k in lmap for k in cand):\n",
    "            return [lmap[k] for k in cand]\n",
    "    raise ValueError(f\"Could not find suitable text columns in: {cols}\")\n",
    "\n",
    "text_cols = guess_text_cols(train_ds.column_names)\n",
    "\n",
    "def build_text_batch(examples):\n",
    "    if len(text_cols) == 1:\n",
    "        return examples[text_cols[0]]\n",
    "    parts = [examples[c] for c in text_cols]\n",
    "    return [\" \".join(items) for items in zip(*parts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c393ab-f683-43b4-8cdc-1e66be80d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Tokenizer + preprocessing\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "max_length = 128\n",
    "\n",
    "def preprocess(examples):\n",
    "    texts = build_text_batch(examples)\n",
    "    return tokenizer(texts, truncation=True, max_length=max_length)\n",
    "\n",
    "def keep_cols(ds):\n",
    "    # Keep all columns except 'labels' (which will be added back after tokenization)\n",
    "    return [c for c in ds.column_names if c != \"labels\"]\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=True, remove_columns=keep_cols(train_ds))\n",
    "val_ds = val_ds.map(preprocess, batched=True, remove_columns=keep_cols(val_ds))\n",
    "if test_ds is not None:\n",
    "    test_ds = test_ds.map(preprocess, batched=True, remove_columns=keep_cols(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39c9625-c963-4120-ae93-a66f5f337645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train unique labels: [0, 1, 2, 3]\n",
      "val unique labels: [0, 1, 2, 3]\n",
      "test unique labels: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# 6) Fix labels: convert 1-based labels to 0-based\n",
    "def to_zero_based(ds):\n",
    "    uniq = ds.unique(\"labels\")\n",
    "    if min(uniq) == 1 and max(uniq) == len(uniq):\n",
    "        return ds.map(lambda ex: {\"labels\": ex[\"labels\"] - 1})\n",
    "    return ds\n",
    "\n",
    "train_ds = to_zero_based(train_ds)\n",
    "val_ds = to_zero_based(val_ds)\n",
    "if test_ds is not None:\n",
    "    test_ds = to_zero_based(test_ds)\n",
    "\n",
    "print(\"train unique labels:\", sorted(set(train_ds[\"labels\"])))\n",
    "print(\"val unique labels:\", sorted(set(val_ds[\"labels\"])))\n",
    "if test_ds is not None:\n",
    "    print(\"test unique labels:\", sorted(set(test_ds[\"labels\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0dbdc9-e156-442f-89f5-850aa2ddd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Cast labels to ClassLabel with names (AG News labels)\n",
    "label_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "train_ds = train_ds.cast_column(\"labels\", ClassLabel(names=label_names))\n",
    "val_ds = val_ds.cast_column(\"labels\", ClassLabel(names=label_names))\n",
    "if test_ds is not None:\n",
    "    test_ds = test_ds.cast_column(\"labels\", ClassLabel(names=label_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8317cd9-03eb-44a1-a918-06a905edfd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Prepare label mappings and num_labels\n",
    "num_labels = len(label_names)\n",
    "id2label = {i: n for i, n in enumerate(label_names)}\n",
    "label2id = {n: i for i, n in enumerate(label_names)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d0d72f-af54-41db-8642-560519b7b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 9) Load model with correct num_labels and label mappings\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0138bcb-cd73-4c54-b55c-01c9d155ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Metrics\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1_macro = f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}\n",
    "\n",
    "# --- Select smaller subsets for faster training ---\n",
    "\n",
    "small_train_ds = train_ds.shuffle(seed=42).select(range(2500))\n",
    "small_val_ds = val_ds.shuffle(seed=42).select(range(500))\n",
    "small_test_ds = test_ds.shuffle(seed=42).select(range(1000)) if test_ds is not None else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa69333-4a17-4b5d-9dcc-acf9facbe998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Precision flags - disable fp16/bf16 for CPU\n",
    "bf16 = False\n",
    "fp16 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f169e26d-fe15-4525-a8f4-fcc3ee339699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/bert-ag-news-sh0416\",\n",
    "    eval_strategy=IntervalStrategy.EPOCH,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # CPU friendly batch size\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    bf16=bf16,\n",
    "    fp16=fp16,\n",
    "    report_to=\"none\",\n",
    "    dataloader_pin_memory=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf97f9bf-72a4-4b3d-9c06-d8f4b7dbeefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YC\\AppData\\Local\\Temp\\ipykernel_17228\\3249139993.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 13) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_ds,\n",
    "    eval_dataset=small_val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6352877b-904f-450d-9f35-fc3b90a39daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='939' max='939' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [939/939 1:50:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.320552</td>\n",
       "      <td>0.912000</td>\n",
       "      <td>0.909377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>0.394020</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.904073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.417194</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.906513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 05:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'eval_loss': 0.3205519914627075, 'eval_accuracy': 0.912, 'eval_f1_macro': 0.9093769457564722, 'eval_runtime': 117.9185, 'eval_samples_per_second': 4.24, 'eval_steps_per_second': 0.271, 'epoch': 3.0}\n",
      "Test metrics: {'eval_loss': 0.35751891136169434, 'eval_accuracy': 0.899, 'eval_f1_macro': 0.89913142996581, 'eval_runtime': 200.007, 'eval_samples_per_second': 5.0, 'eval_steps_per_second': 0.315, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# 14) Train + Evaluate\n",
    "trainer.train()\n",
    "print(\"Validation metrics:\", trainer.evaluate(small_val_ds))\n",
    "if small_test_ds is not None:\n",
    "    print(\"Test metrics:\", trainer.evaluate(small_test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380ee2a-e8cb-44c5-a4e5-7aef5215e3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
