{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c98767-3e62-4a85-975a-6e05c7844f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in d:\\anaconda\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.55.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\anaconda\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->kagglehub) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub transformers scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fa8951-5de7-4105-9843-2fbcc900ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72cb5cb8-3428-48ea-b71d-fa7b1cc3c538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded at: C:\\Users\\YC\\.cache\\kagglehub\\datasets\\suraj520\\customer-support-ticket-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "#Step 1 Download Dataset\n",
    "path = kagglehub.dataset_download(\"suraj520/customer-support-ticket-dataset\")\n",
    "print(\"Dataset downloaded at:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b78473-cf2a-4fda-bcd0-7daa07d8da93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSV file: C:\\Users\\YC\\.cache\\kagglehub\\datasets\\suraj520\\customer-support-ticket-dataset\\versions\\1\\customer_support_tickets.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Locate CSV file inside downloaded folder\n",
    "p = Path(path)\n",
    "csv_files = list(p.rglob(\"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(\"No CSV files found in dataset folder.\")\n",
    "csv_path = csv_files[0]\n",
    "print(\"Using CSV file:\", csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa45848-3da2-404f-92d7-6841bbab42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8469, 17)\n",
      "Columns: ['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age', 'Customer Gender', 'Product Purchased', 'Date of Purchase', 'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status', 'Resolution', 'Ticket Priority', 'Ticket Channel', 'First Response Time', 'Time to Resolution', 'Customer Satisfaction Rating']\n",
      "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
      "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
      "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
      "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
      "\n",
      "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
      "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
      "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
      "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
      "\n",
      "             Ticket Subject  \\\n",
      "0             Product setup   \n",
      "1  Peripheral compatibility   \n",
      "2           Network problem   \n",
      "\n",
      "                                  Ticket Description  \\\n",
      "0  I'm having an issue with the {product_purchase...   \n",
      "1  I'm having an issue with the {product_purchase...   \n",
      "2  I'm facing a problem with my {product_purchase...   \n",
      "\n",
      "               Ticket Status                                    Resolution  \\\n",
      "0  Pending Customer Response                                           NaN   \n",
      "1  Pending Customer Response                                           NaN   \n",
      "2                     Closed  Case maybe show recently my computer follow.   \n",
      "\n",
      "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
      "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
      "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
      "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
      "\n",
      "   Customer Satisfaction Rating  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           3.0  \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load dataset\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8b6867-fd6c-4916-9889-00ca7dbcfd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ticket ID', 'Customer Name', 'Customer Email', 'Customer Age', 'Customer Gender', 'Product Purchased', 'Date of Purchase', 'Ticket Type', 'Ticket Subject', 'Ticket Description', 'Ticket Status', 'Resolution', 'Ticket Priority', 'Ticket Channel', 'First Response Time', 'Time to Resolution', 'Customer Satisfaction Rating']\n"
     ]
    }
   ],
   "source": [
    "#step 4 print columns \n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84561dfa-e6ba-4504-bfad-c11e1d23fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text column: Ticket Description\n",
      "Using label column: Ticket Type\n"
     ]
    }
   ],
   "source": [
    "#step 5 Assign text and label columns \n",
    "text_col = \"Ticket Description\" \n",
    "label_col = \"Ticket Type\"        \n",
    "\n",
    "print(f\"Using text column: {text_col}\")\n",
    "print(f\"Using label column: {label_col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf097436-40a7-4269-b4a2-c15c44b80b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using labels (top 10): ['Refund request', 'Technical issue', 'Cancellation request', 'Product inquiry', 'Billing inquiry']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare candidate labels (top 10 frequent labels)\n",
    "label_counts = df[label_col].value_counts()\n",
    "labels = label_counts.head(10).index.tolist()\n",
    "print(f\"Using labels (top 10): {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55e3582-5ae8-4bdf-ae2b-7e89e297ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46726646e09c43a4bcd26cfba453c61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dad9f639b0b47ca835f2c592c846add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a799ee443a44399f95e394d989c6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/258 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7faab3809f84d49af33d9b0fefa3bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4e8a6d759946e3840a5f9c6eb65a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Initialize zero-shot classification pipeline\n",
    "model_name = \"typeform/distilbert-base-uncased-mnli\"  # smaller, faster on CPU\n",
    "classifier = pipeline(\"zero-shot-classification\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9abdaa-c717-473f-985e-ad874d518130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running zero-shot classification on sample data...\n",
      "Top-1 Accuracy: 0.1900\n",
      "Macro F1 Score (Top-1): 0.1016\n",
      "Top-3 Accuracy: 0.6167\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Sample subset for evaluation (optional)\n",
    "eval_df = df[[text_col, label_col]].dropna().sample(min(300, len(df)), random_state=42)\n",
    "\n",
    "top1_preds = []\n",
    "y_true = []\n",
    "top3_hits = 0\n",
    "\n",
    "print(\"Running zero-shot classification on sample data...\")\n",
    "\n",
    "for idx, row in eval_df.iterrows():\n",
    "    text = row[text_col]\n",
    "    true_label = row[label_col]\n",
    "    result = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    \n",
    "    ranked_labels = [label for label, score in sorted(zip(result[\"labels\"], result[\"scores\"]), key=lambda x: x[1], reverse=True)]\n",
    "    \n",
    "    top1_preds.append(ranked_labels[0])\n",
    "    y_true.append(true_label)\n",
    "    \n",
    "    if true_label in ranked_labels[:3]:\n",
    "        top3_hits += 1\n",
    "\n",
    "acc_top1 = accuracy_score(y_true, top1_preds)\n",
    "f1_macro = f1_score(y_true, top1_preds, average=\"macro\")\n",
    "acc_top3 = top3_hits / len(eval_df)\n",
    "\n",
    "print(f\"Top-1 Accuracy: {acc_top1:.4f}\")\n",
    "print(f\"Macro F1 Score (Top-1): {f1_macro:.4f}\")\n",
    "print(f\"Top-3 Accuracy: {acc_top3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f70f1ef-7332-479f-a3fb-438ccbd1b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Function to predict top 3 tags for new ticket text\n",
    "def predict_top3_tags(text):\n",
    "    out = classifier(text, candidate_labels=labels, multi_label=True)\n",
    "    sorted_labels = sorted(zip(out[\"labels\"], out[\"scores\"]), key=lambda x: x[1], reverse=True)\n",
    "    return {label: float(score) for label, score in sorted_labels[:3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "992df843-5a45-402e-872c-d5d04521b10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample text: I am unable to login to my account after the password reset.\n",
      "Predicted top 3 tags: {'Technical issue': 0.5089683532714844, 'Refund request': 0.08350994437932968, 'Cancellation request': 0.020151687785983086}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sample_text = \"I am unable to login to my account after the password reset.\"\n",
    "print(f\"\\nSample text: {sample_text}\")\n",
    "print(\"Predicted top 3 tags:\", predict_top3_tags(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a70e3-ae55-4f94-86c4-67b7fc34b132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
